# NTTが提供する対話モデルの利用に関する注意文


## 対話モデルの提供について
NTT コミュニケーション科学基礎研究所（以下，NTT）が提供する本対話モデルは，対話的な応答文を生成するプログラム（対話プログラム）の動作に必要な，パラメータデータです．本対話モデルは，人同士の対話データを利用して学習（パラメータ調整）されています．本対話モデルを対話プログラムと合わせて利用することで，学習に用いられた対話データに含まれる応答関係の出現確率に基づいて，応答文を確率的に生成することができます．

対話プログラムの研究開発に携わる多くの方々に本モデルを適切にご利用いただくことで，様々な技術的課題を解決し，対話システム研究を大きく進展させることができると考え，このたび評価・検証目的のご利用に限り，本モデルを無償で公開することとなりました．

## 提供モデルの利用用途の制限
本対話モデルの利用用途は，本モデルの対話モデル性能の評価・検証目的に限られます．評価・検証を目的とする限りにおいて，営利団体・非営利団体・個人を問わず，本モデルを一般ユーザとの対話にもご利用いただけます．
一方で，営利団体・非営利団体・個人を問わず，また商用・非商用を問わず，対話サービスの提供自体を目的とする用途への利用はご遠慮いただいております．そうした目的へのご利用を検討される場合は，末尾の問い合わせ先へご連絡ください． 

## 注意事項
本モデルを利用した対話プログラムを通じて生成される文には，原理的に学習データに含まれる内容の偏りが反映されます．本対話モデルの学習に利用した対話データにはWeb上の公開情報から収集した文が含まれるため，Web上の文の分布を反映して，非社会的な発話，実在人物・組織等に対する誹謗中傷，ヘイトスピーチ等の，不適切な内容を含む文が生成される可能性があります．
実際にどのような文が生成されるかは，対話プログラムのアルゴリズムや使い方に大きく依存します．そのため，本モデルの利用者（対話プログラムと本モデルを利用して，文を生成した者）は，生成される文が不適切な内容を含む可能性を考慮した上で本モデルを利用し，生成された文によって被害が生じないよう万全の配慮と対策をお願いいたします．利用者は，そのような配慮と対策をおこない，適切・不適切を問わず生成した文に対する責任を負うことに同意する場合に限り，本モデルをご利用いただけます。

## 不適切文生成への対策例
NTTが本モデルを実際の対話に適用する場合には，一般に以下の対策を取っております．ただし現状では不適切文生成への対応自体も解決すべき技術的課題のひとつであり，下記の例が十分な対策であることをNTTが保証するものではありません．あくまでも参考としてお考えください．
1. モデル利用時に想定される入力文や，不適切な文の生成を誘発させうる入力文を事前に与えて応答を十分にテストする
2. 実際に生成文を見る人に「不適切な文が出力されうる」ことを告知し了解を得る
3. 高い確率で特定の不適切表現が生成される場合には，キーワードフィルタで当該表現を含む文の出力を抑制する
4. 生成文を見た人が不快に感じた場合には即座に対話を中止する


## 提供対話モデルの詳細

### 事前学習モデル
Twitter内の応答ツイートペアのみを用いて，幅広い言語表現や応答関係を不適切な内容も含めて学習したモデルです．不適切な内容（例えば犯罪行為）を除去したデータでモデルを学習した場合，入力された情報の適切さを判断する基準そのものがモデルから失われてしまいます．そのため，あえて不適切な内容を除去せずに学習しています．
後述する「ファインチューン済みモデル」の素材として用いられるモデルであり，本モデルをそのまま実際の対話へ適用することは想定されていません．実際の対話へ適用する場合は，適切なデータでファインチューン（追加学習）を行ってからご利用ください．

### ファインチューン済みモデル
事前学習モデルを下地として，不適切な発話が含まれない対話データ（NTTが収集した日本語版「Persona-chat」「Empathetic dialog」）で追加学習（ファインチューン）したモデルです．十分な量の対話データを持たない利用者が，本対話モデルの性能を予備的に検証する目的で提供します．
ファインチューンに利用した対話データの性質が反映されるため，不適切な文の生成確率は事前学習モデルに比べて大幅に低下していますが，完全には抑制されていません．特に，不適切な内容がモデルに入力された場合には，その返答として不適切な内容が生成される確率が上昇します．注意事項や不適切文生成への対策例をご参考いただき，モデル利用者が必要と考える対策を施した上でご利用ください．

## お問合せ先
dialog-transformer-ml < at > hco.ntt.co.jp